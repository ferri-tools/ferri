# Ferri

Ferri is a local-first AI toolkit that acts as an intelligent director for foundation models. It evolves from a simple command runner into a proactive, agentic partner that can plan and execute complex development tasks.

Ferri creates secure, project-based environments with portable context, unifying your workflow across local (Ollama) and remote (API) models. The goal is to let you focus on your high-level goals, not on the minutiae of context management and command execution.

## The Ferri Architecture

Ferri is built in layers, allowing you to choose the right level of power for your task.

| Layer | Command(s) | Description |
|---|---|---|
| **L1: Core Execution** | `init`, `secrets`, `ctx`, `with` | The foundation. Manages your environment and executes synchronous, single-shot commands with injected context and secrets. |
| **L2: Workflow Automation** | `run`, `ps`, `yank`, `flow` | The automation layer. Runs commands as background jobs, monitors their status, retrieves their output, and orchestrates multi-step workflows. |
| **L3: Agentic Engine** | `do` | The intelligent director. Takes a high-level goal, formulates a multi-step plan, and executes it. Supports interactive debugging to pause and get user feedback on errors. |

## Interactive Features

Ferri is designed for a tight feedback loop. When things go wrong, you have tools to see what's happening and intervene.

*   **Interactive Job Dashboard:** Use `ferri ps --interactive` to launch a terminal-based UI where you can see the real-time status of all running jobs, inspect their logs, and visualize workflow dependencies.
*   **Interactive Debugging:** When the agent encounters an error, it can pause execution and ask for your input, turning a failed run into a collaborative debugging session.

## Command Modifiers

Modifiers augment the behavior of Ferri's core commands, adding powerful capabilities for streaming, interactivity, safety, and more.

### General Modifiers

*   **`--stream`**
    *   **Applies to**: `with`, `run`, `do`
    *   **Description**: Streams the output token-by-token as it's generated by the model. This is useful for observing the progress of long-running tasks or getting immediate feedback.
    *   **Creative Example**: Watch an AI generate a story in real-time, right in your terminal.
        ```bash
        ferri with --stream --model ollama/mistral "Tell me a short story about a robot who discovers music."
        ```

*   **`--model <model_name>`**
    *   **Applies to**: `with`, `run`, `do`
    *   **Description**: Specifies which model to use for a given command (e.g., `ollama/llama3`, `openai/gpt-4o`). This overrides any project-level default model.
    *   **Creative Example**: Quickly compare the outputs of two different models for the same task.
        ```bash
        # Get a response from a local model
        ferri run --model ollama/llama3 "Explain quantum computing" > llama3_explanation.txt
        # Get a response from a remote model
        ferri run --model openai/gpt-4o "Explain quantum computing" > gpt4_explanation.txt
        ```

*   **`--no-cache`**
    *   **Applies to**: `with`, `run`, `do`
    *   **Description**: Forces the command to be re-executed and ignores any cached results. By default, Ferri caches responses to identical prompts to save time and resources.
    *   **Creative Example**: When you're iterating on a prompt and want to ensure you're getting a fresh, non-deterministic response every time.
        ```bash
        ferri with --no-cache "Brainstorm three creative names for a new coffee brand."
        ```

*   **`--silent`**
    *   **Applies to**: `run`, `flow`
    *   **Description**: Suppresses all output to stdout. The command runs in the background without printing job IDs or status updates, which is useful for scripting.
    *   **Creative Example**: Integrate Ferri into a larger bash script without cluttering the console output.
        ```bash
        echo "Generating documentation..."
        ferri flow run --silent docs-gen.yml
        echo "Documentation generation complete."
        ```

### Context & Data Handling

*   **`--ttl <duration>`**
    *   **Applies to**: `ctx`
    *   **Description**: Sets a "time-to-live" for a piece of context (e.g., `--ttl 1h`, `--ttl 30m`). The context is automatically removed after the duration expires.
    *   **Creative Example**: Add a temporary API response to the context that you only need for the next few minutes.
        ```bash
        # Add the output of a job to the context, but have it expire in 10 minutes.
        ferri ctx add --from-job get_api_data --as temp_data.json --ttl 10m
        ```

*   **`--format <prompt>`**
    *   **Applies to**: `ctx`, `yank`
    *   **Description**: Processes data with a one-shot AI transformation *as it's being added to the context*. This keeps your context clean and efficient.
    *   **Creative Example**: Scrape a complex JSON object but only add the relevant parts to your context.
        ```bash
        # Yank raw JSON, but use --format to transform it into a clean list of names.
        ferri ctx add --from-job get_users_job --as user_list.txt \
          --format "Extract only the 'username' from each object in this JSON array and list them, one per line."
        ```

### Workflow & Job Control

*   **`--interactive`**
    *   **Applies to**: `ps`, `do`
    *   **Description**: For `ps`, it launches a terminal UI to manage jobs. For `do`, it enables a collaborative debugging session where the agent pauses on error and asks for user input.
    *   **Creative Example**: Your agent fails to parse a file. Instead of stopping, it asks you for help.
        ```bash
        # Agent encounters an error...
        # AGENT: "Error: Could not parse 'api_spec.yaml'. The format seems invalid. How should I proceed?"
        # You can then provide guidance to unblock the agent.
        ferri do --interactive "Generate API clients from 'api_spec.yaml'"
        ```

*   **`--retry <attempts>`**
    *   **Applies to**: `run`, `flow`
    *   **Description**: Automatically retries a failed job or workflow step a specified number of times.
    *   **Creative Example**: A job that calls a flaky web service can be made more resilient.
        ```bash
        # This job will try up to 3 times before failing.
        ferri run --retry 3 -- ./scripts/fetch_flaky_service.sh
        ```

*   **`--parallel`**
    *   **Applies to**: `flow`
    *   **Description**: Executes all jobs in a workflow that don't have dependencies on each other in parallel, speeding up execution.
    *   **Creative Example**: A workflow that generates documentation for three independent modules can run them all at once instead of sequentially.
        ```yaml
        # ci-prep.yml
        name: "Prepare for CI"
        jobs:
          - id: docs-auth
            command: 'ferri with --ctx src/auth/** > docs/auth.md'
          - id: docs-api
            command: 'ferri with --ctx src/api/** > docs/api.md'
          - id: docs-db
            command: 'ferri with --ctx src/db/** > docs/db.md'
        ```
        ```bash
        # This will run all three doc generation jobs simultaneously.
        ferri flow run --parallel ci-prep.yml
        ```

### Safety & Planning

*   **`--dry-run`**
    *   **Applies to**: `do`, `flow`
    *   **Description**: Generates and displays the execution plan without actually running any commands. This is invaluable for debugging and safely previewing an agent's intentions.
    *   **Creative Example**: Before committing to a complex refactor, see exactly what the agent is planning.
        ```bash
        ferri do --dry-run "Migrate the database connection from mysql2 to pg."

        # Ferri's Output:
        # DRY RUN: The following plan will be executed:
        # 1. READ package.json
        # 2. RUN npm install pg
        # 3. MODIFY src/database.js to replace mysql2 connection logic with pg.
        # 4. RUN npm uninstall mysql2
        ```

*   **`--gate <prompt>`**
    *   **Applies to**: `flow` (within the YAML file)
    *   **Description**: Adds a manual approval gate to a workflow. The workflow pauses and prompts the user before proceeding.
    *   **Creative Example**: A workflow that refactors code and then deploys it, requiring your sign-off.
        `deploy.yml:`
        ```yaml
        name: "Refactor and Deploy"
        jobs:
          - id: refactor-api
            command: 'ferri do "Refactor the authentication module to use JWTs."'
          - id: deploy-to-staging
            dependencies: [refactor-api]
            command: './scripts/deploy_staging.sh'
            gate: "The API has been refactored. Proceed with deployment to staging?"
        ```

*   **`--budget <amount>`**
    *   **Applies to**: `do`, `flow`
    *   **Description**: Sets a maximum cost (e.g., `$0.50`) for a task that uses remote models, preventing runaway costs.
    *   **Creative Example**: Let an agent research a topic without risking a high API bill.
        ```bash
        ferri do --model openai/gpt-4o --budget 1.00 \
          "Research the latest advancements in quantum computing and write a 5-page summary."
        ```

## Usage Examples

### 1. Basic Execution (`with`)

Run a one-shot command to get a quick answer from a local model.

```bash
# Initialize project and add context
ferri init
ferri ctx add ./src

# Query a local model via Ollama
ferri with --ctx -- ollama run llama3 "Based on the code, what is the primary goal of this project?"
```

### 2. The Asynchronous Workflow (`run`, `ps`, `yank`, `ctx`)

For long-running tasks, submit a job, monitor it, and then "yank" the result directly into your context for the next step. This creates a powerful feedback loop.

```bash
# Step 1: Run a job to generate documentation. It returns a Job ID instantly.
ferri run -- ferri with --ctx src/main.rs --model gemma "Generate a summary of this Rust module"
=> Job submitted: job-b4c5d6

# Step 2: Check the status of your job.
ferri ps
  JOB ID      STATUS      COMMAND
  job-b4c5d6  COMPLETED   ferri with --ctx src/main.rs...

# Step 3: Directly add the job's output to the context as a new virtual file.
# This avoids creating temporary files and keeps the workflow clean.
ferri ctx add --from-job job-b4c5d6 --as module_summary.md
=> Added output from job-b4c5d6 to context as 'module_summary.md'

# Step 4: Use the newly created context in your next command.
ferri with --ctx --model gemma "Based on the summary, write three potential refactors for this module"
```

### 3. Advanced Workflow (`flow`)

Define a multi-step process in a YAML file to automate repetitive tasks.

`ci-prep.yml:`
```yaml
name: "Prepare for CI"
jobs:
  - id: generate-docs
    description: "Generate documentation for all source files."
    command: 'ferri with --ctx --model gpt-4o "Generate technical markdown docs for the codebase" > DOCS.md'

  - id: write-tests
    description: "Write unit tests based on the new documentation."
    dependencies: [generate-docs]
    command: 'ferri with --ctx DOCS.md --model gpt-4o "Write unit tests for the main module" > main.test.js'
```

```bash
# Execute the entire workflow
ferri flow run ci-prep.yml
```

### 4. Agentic Task (`do`)

Give Ferri a high-level objective and let it figure out the steps.

```bash
# Tell Ferri what you want to achieve
ferri do "Add a new '/api/users' endpoint to my Express app. It should have a route, a controller with a placeholder function, and be registered in the main app file."

# Ferri will generate and propose a plan for your approval:
# PLAN:
# 1. Create file: src/routes/users.js
# 2. Create file: src/controllers/users.js
# 3. Modify file: src/app.js to import and use the new router.
# Proceed? [y/N]
```

## Commands

```
Usage: ferri [OPTIONS] COMMAND [ARGS]...

  Ferri is a local-first AI toolkit that acts as an intelligent director
  for foundation models.

Options:
  -v, --verbose    Enable verbose output for debugging.
  -h, --help       Show this message and exit.

Commands:
  init        Initialize a new Ferri project in the current directory.
  secrets     Manage encrypted, project-specific secrets like API keys.
  ctx         Manage the project's context from files or job outputs.
  with        Execute a command within a context-aware, synchronous environment.
  run         Run a command as a long-running background job.
  ps          List and manage active background jobs.
  yank        Fetch the output (stdout) of a completed background job.
  flow        Define and run multi-step, declarative AI workflows from a file.
  do          Execute a high-level goal with an AI-powered agentic engine.
```
$ ferri --help

Usage: ferri [OPTIONS] COMMAND [ARGS]...

  Ferri is a local-first AI toolkit that acts as an intelligent director for
  foundation models. It creates secure, project-based environments with
  portable context, unifying your workflow across local (Ollama) and remote
  (API) models.

  The goal is to let you focus on code, not on context management.

Options:
  -v, --verbose    Enable verbose output for debugging.
  --version        Show the version number and exit.
  -h, --help       Show this message and exit.

Commands:
  init        Initialize a new Ferri project in the current directory.
  secrets     Manage encrypted, project-specific secrets like API keys.
  ctx         Manage the project's context (files and directories).
  with        Execute a command within a context-aware environment.
  run         (Coming Soon) Run a command as a long-running background job.
  ps          (Coming Soon) List and manage active background jobs.
  flow        (Coming Soon) Define and run multi-step, declarative AI workflows.

-----------------------------------------------------------------------------

EXAMPLES OF COMMON USE CASES:

1. Code Comprehension with a Local Model:
   Ask questions about your codebase using a fast, local model running via Ollama.

   # First, initialize Ferri and define the context for your project
   $ ferri init
   $ ferri ctx add ./src ./docs README.md

   # Now, ask a question. Ferri injects your context into the prompt automatically.
   $ ferri with --ctx -- ollama run llama3 "Based on the files in ./src, what is the primary purpose of this application?"


2. Code Generation with a Remote Model:
   Use a powerful remote model to generate a new file, saving the output directly.

   # Store your API key securely once
   $ ferri secrets set OPENAI_API_KEY="sk-..."

   # Use the '--model' flag to switch to a remote API and '--output' to save the result.
   # Ferri handles auth and context injection for you.
   $ ferri with --ctx --model gpt-4o --output ./tests/main.test.js "Write a comprehensive test suite for the main function in the source code."


3. Interactive Refactoring (Advanced):
   Give the model direct, supervised control to modify your files. Ferri will
   show you a plan and ask for confirmation before any changes are made.

   # The '--interactive' flag enables the model to plan and execute file writes/deletes.
   $ ferri with --ctx --interactive --model gpt-4o "Refactor the database logic from server.js into its own module at ./src/db.js and update server.js to use it."

   > Ferri will first output the model's plan:
   > [PLAN]
   > 1. Create a new file ./src/db.js with the database connection logic.
   > 2. Modify ./src/server.js to import and use the new module.
   > Proceed with this plan? [y/n]


4. Using Ferri as a Secure Script Runner:
   Run any local script or tool that needs secrets, without exposing them in your
   shell history or hardcoding them.

   # Your python script can now access the API key via standard environment variables.
   $ ferri with -- python ./scripts/deploy.py

   # (Inside deploy.py)
   # import os
   # api_key = os.getenv("OPENAI_API_KEY")


For more detailed help on a specific command, run 'ferri <COMMAND> --help'.